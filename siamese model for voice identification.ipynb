{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io.wavfile import read, write\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "import pylab\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import shutil\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D, Lambda, Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D, Lambda, Layer\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create spectogram from wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flac_to_wav(flac_path, wav_path):\n",
    "    audio, sr = soundfile.read(flac_path)\n",
    "    soundfile.write(wav_path, audio, sr, 'PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting_silence(path):\n",
    "    rate, data = read(path)\n",
    "    new_audio = librosa.effects.trim(np.array(read(path)[1],dtype=float), top_db = 20)[0]\n",
    "    new_audio = new_audio[0:80000]\n",
    "    #new_audio_2 = new_audio[-80000:]\n",
    "    return (new_audio, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(sound, rate, sp_path):\n",
    "    sound_info, frame_rate = sound, rate\n",
    "    pylab.figure(num=None, figsize=(10,10))\n",
    "    pylab.axis('off')\n",
    "    pylab.specgram(sound_info, Fs=frame_rate)\n",
    "\n",
    "    pylab.savefig(sp_path,pad_inches = 0, transparent = True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1, 151):\n",
    "    os.mkdir(\"/Users/nastyastrashnova/Study/masters/BigDataset/audio/%s\" %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,151):\n",
    "    for audio in os.listdir(\"/Users/nastyastrashnova/Downloads/zw4p4p7sdh-1/differentPhrase/%s\" % i):\n",
    "        flac_to_wav(\"/Users/nastyastrashnova/Downloads/zw4p4p7sdh-1/differentPhrase/%s/%s\" %(i, audio),\n",
    "                \"/Users/nastyastrashnova/Study/masters/BigDataset/audio/%s/%s.wav\" %(i, audio[-6:-5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_audio = \"/Users/nastyastrashnova/Study/masters/BigDataset/audio/\"\n",
    "path_to_anchor = \"/Users/nastyastrashnova/Study/masters/BigDataset/anchor/\"\n",
    "path_to_positive = \"/Users/nastyastrashnova/Study/masters/BigDataset/positive/\"\n",
    "path_to_negative = \"/Users/nastyastrashnova/Study/masters/BigDataset/negative/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "count = 200\n",
    "for i in range(75):\n",
    "    num = i*2 + 1\n",
    "    path = (path_to_audio+\"%s/\" %num)\n",
    "    # anchor\n",
    "    sound, rate = cutting_silence(path + \"1.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_anchor + \"%s.png\" %count)\n",
    "    #print(path + \"1.wav\", \"--------\",  path_to_anchor + \"%s.png\" %count )\n",
    "\n",
    "    sound, rate = cutting_silence(path + \"2.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_anchor + \"%s.png\" %(count+1))\n",
    "    #print(path + \"2.wav\", \"--------\",  path_to_anchor + \"%s.png\" %(count+1) )\n",
    "               \n",
    "                      \n",
    "    # positive\n",
    "    sound, rate = cutting_silence(path + \"3.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_positive + \"%s.png\" %count)\n",
    "    #print(path + \"3.wav\", \"--------\",  path_to_positive  + \"%s.png\" %(count) )\n",
    "                      \n",
    "    sound, rate = cutting_silence(path + \"4.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_positive + \"%s.png\" %(count+1))\n",
    "    #print(path + \"4.wav\", \"--------\",  path_to_positive  + \"%s.png\" %(count+1) )\n",
    "                      \n",
    "                      \n",
    "    # negative\n",
    "    num = i*2 + 2\n",
    "    path = (path_to_audio+\"%s/\" %num)\n",
    "                      \n",
    "    sound, rate = cutting_silence(path + \"1.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_negative + \"%s.png\" %count)\n",
    "    #print(path + \"1.wav\", \"--------\",  path_to_negative  + \"%s.png\" %(count) )\n",
    "                      \n",
    "    sound, rate = cutting_silence(path + \"2.wav\")\n",
    "    graph_spectrogram(sound, rate, path_to_negative + \"%s.png\" %(count+1))\n",
    "    #print(path + \"2.wav\", \"--------\",  path_to_negative  + \"%s.png\" %(count+1) )\n",
    "                      \n",
    "    count = count + 2\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = ('/Users/nastyastrashnova/Study/masters/BigDataset/')\n",
    "ANC_PATH = (dataset_path + 'anchor')\n",
    "POS_PATH = (dataset_path + 'positive')\n",
    "NEG_PATH = (dataset_path + 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.png', shuffle=False)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'/*.png', shuffle=False)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.png', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    img = tf.image.resize(img, (100,100))\n",
    "\n",
    "    img = img / 255.0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pair images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)\n",
    "\n",
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(): \n",
    "    inp = Input(shape=(100,100,4), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Forth block \n",
    "    c3 = Conv2D(256, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class LossFunction(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = LossFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,4))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(100,100,4))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = LossFunction()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          [(None, 100, 100, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "validation_img (InputLayer)     [(None, 100, 100, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Functional)          (None, 4096)         39753408    input_img[0][0]                  \n",
      "                                                                 validation_img[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "distance (LossFunction)         (None, 4096)         0           embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        distance[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 39,757,505\n",
      "Trainable params: 39,757,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4) # 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Establish Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Build Train Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Build Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data, EPOCHS = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/3\n",
      "tf.Tensor(0.19025558, shape=(), dtype=float32)\n",
      " 1/29 [>.............................] - ETA: 4:58tf.Tensor(0.20177506, shape=(), dtype=float32)\n",
      " 2/29 [=>............................] - ETA: 4:34tf.Tensor(0.24511866, shape=(), dtype=float32)\n",
      " 3/29 [==>...........................] - ETA: 4:18tf.Tensor(0.24609987, shape=(), dtype=float32)\n",
      " 4/29 [===>..........................] - ETA: 4:06tf.Tensor(0.23645984, shape=(), dtype=float32)\n",
      " 5/29 [====>.........................] - ETA: 3:57tf.Tensor(0.2802189, shape=(), dtype=float32)\n",
      " 6/29 [=====>........................] - ETA: 3:46tf.Tensor(0.2029315, shape=(), dtype=float32)\n",
      " 7/29 [======>.......................] - ETA: 3:36tf.Tensor(0.24305055, shape=(), dtype=float32)\n",
      " 8/29 [=======>......................] - ETA: 3:25tf.Tensor(0.31378403, shape=(), dtype=float32)\n",
      " 9/29 [========>.....................] - ETA: 3:15tf.Tensor(0.076868005, shape=(), dtype=float32)\n",
      "10/29 [=========>....................] - ETA: 3:05tf.Tensor(0.18907365, shape=(), dtype=float32)\n",
      "11/29 [==========>...................] - ETA: 2:56tf.Tensor(0.2883154, shape=(), dtype=float32)\n",
      "12/29 [===========>..................] - ETA: 2:46tf.Tensor(0.0927083, shape=(), dtype=float32)\n",
      "13/29 [============>.................] - ETA: 2:36tf.Tensor(0.24661869, shape=(), dtype=float32)\n",
      "14/29 [=============>................] - ETA: 2:26tf.Tensor(0.096595116, shape=(), dtype=float32)\n",
      "15/29 [==============>...............] - ETA: 2:16tf.Tensor(0.29092485, shape=(), dtype=float32)\n",
      "16/29 [===============>..............] - ETA: 2:07tf.Tensor(0.15650307, shape=(), dtype=float32)\n",
      "17/29 [================>.............] - ETA: 1:57tf.Tensor(0.25704956, shape=(), dtype=float32)\n",
      "18/29 [=================>............] - ETA: 1:47tf.Tensor(0.2886724, shape=(), dtype=float32)\n",
      "19/29 [==================>...........] - ETA: 1:37tf.Tensor(0.17152414, shape=(), dtype=float32)\n",
      "20/29 [===================>..........] - ETA: 1:27tf.Tensor(0.13042971, shape=(), dtype=float32)\n",
      "21/29 [====================>.........] - ETA: 1:18tf.Tensor(0.09298336, shape=(), dtype=float32)\n",
      "22/29 [=====================>........] - ETA: 1:08tf.Tensor(0.21285465, shape=(), dtype=float32)\n",
      "23/29 [======================>.......] - ETA: 58s tf.Tensor(0.32146537, shape=(), dtype=float32)\n",
      "24/29 [=======================>......] - ETA: 48stf.Tensor(0.1510848, shape=(), dtype=float32)\n",
      "25/29 [========================>.....] - ETA: 39stf.Tensor(0.08620711, shape=(), dtype=float32)\n",
      "26/29 [=========================>....] - ETA: 29stf.Tensor(0.084221385, shape=(), dtype=float32)\n",
      "27/29 [==========================>...] - ETA: 19stf.Tensor(0.10031329, shape=(), dtype=float32)\n",
      "28/29 [===========================>..] - ETA: 9s tf.Tensor(0.4248146, shape=(), dtype=float32)\n",
      "29/29 [==============================] - 281s 10s/step\n",
      "0.4248146 0.93721974 0.9675926\n",
      "\n",
      " Epoch 2/3\n",
      "tf.Tensor(0.16472383, shape=(), dtype=float32)\n",
      " 1/29 [>.............................] - ETA: 4:32tf.Tensor(0.19287482, shape=(), dtype=float32)\n",
      " 2/29 [=>............................] - ETA: 4:21tf.Tensor(0.09122615, shape=(), dtype=float32)\n",
      " 3/29 [==>...........................] - ETA: 4:12tf.Tensor(0.21094373, shape=(), dtype=float32)\n",
      " 4/29 [===>..........................] - ETA: 4:03tf.Tensor(0.16248584, shape=(), dtype=float32)\n",
      " 5/29 [====>.........................] - ETA: 3:53tf.Tensor(0.03975627, shape=(), dtype=float32)\n",
      " 6/29 [=====>........................] - ETA: 3:43tf.Tensor(0.46821442, shape=(), dtype=float32)\n",
      " 7/29 [======>.......................] - ETA: 3:33tf.Tensor(0.28964984, shape=(), dtype=float32)\n",
      " 8/29 [=======>......................] - ETA: 3:23tf.Tensor(0.06003026, shape=(), dtype=float32)\n",
      " 9/29 [========>.....................] - ETA: 3:14tf.Tensor(0.16166326, shape=(), dtype=float32)\n",
      "10/29 [=========>....................] - ETA: 3:04tf.Tensor(0.051820304, shape=(), dtype=float32)\n",
      "11/29 [==========>...................] - ETA: 2:54tf.Tensor(0.116039716, shape=(), dtype=float32)\n",
      "12/29 [===========>..................] - ETA: 2:44tf.Tensor(0.13479054, shape=(), dtype=float32)\n",
      "13/29 [============>.................] - ETA: 2:35tf.Tensor(0.057556324, shape=(), dtype=float32)\n",
      "14/29 [=============>................] - ETA: 2:25tf.Tensor(0.17920806, shape=(), dtype=float32)\n",
      "15/29 [==============>...............] - ETA: 2:15tf.Tensor(0.075877845, shape=(), dtype=float32)\n",
      "16/29 [===============>..............] - ETA: 2:05tf.Tensor(0.056786798, shape=(), dtype=float32)\n",
      "17/29 [================>.............] - ETA: 1:56tf.Tensor(0.3808872, shape=(), dtype=float32)\n",
      "18/29 [=================>............] - ETA: 1:46tf.Tensor(0.12446608, shape=(), dtype=float32)\n",
      "19/29 [==================>...........] - ETA: 1:36tf.Tensor(0.22546202, shape=(), dtype=float32)\n",
      "20/29 [===================>..........] - ETA: 1:27tf.Tensor(0.22768271, shape=(), dtype=float32)\n",
      "21/29 [====================>.........] - ETA: 1:17tf.Tensor(0.14043024, shape=(), dtype=float32)\n",
      "22/29 [=====================>........] - ETA: 1:07tf.Tensor(0.21466492, shape=(), dtype=float32)\n",
      "23/29 [======================>.......] - ETA: 58s tf.Tensor(0.17101748, shape=(), dtype=float32)\n",
      "24/29 [=======================>......] - ETA: 48stf.Tensor(0.089985445, shape=(), dtype=float32)\n",
      "25/29 [========================>.....] - ETA: 38stf.Tensor(0.048965283, shape=(), dtype=float32)\n",
      "26/29 [=========================>....] - ETA: 29stf.Tensor(0.094356075, shape=(), dtype=float32)\n",
      "27/29 [==========================>...] - ETA: 19stf.Tensor(0.33192104, shape=(), dtype=float32)\n",
      "28/29 [===========================>..] - ETA: 9s tf.Tensor(0.33026814, shape=(), dtype=float32)\n",
      "29/29 [==============================] - 280s 10s/step\n",
      "0.33026814 0.97510374 0.9710744\n",
      "\n",
      " Epoch 3/3\n",
      "tf.Tensor(0.28520617, shape=(), dtype=float32)\n",
      " 1/29 [>.............................] - ETA: 4:33tf.Tensor(0.1388022, shape=(), dtype=float32)\n",
      " 2/29 [=>............................] - ETA: 4:23tf.Tensor(0.07766653, shape=(), dtype=float32)\n",
      " 3/29 [==>...........................] - ETA: 4:14tf.Tensor(0.08469199, shape=(), dtype=float32)\n",
      " 4/29 [===>..........................] - ETA: 4:04tf.Tensor(0.13380796, shape=(), dtype=float32)\n",
      " 5/29 [====>.........................] - ETA: 3:54tf.Tensor(0.27651545, shape=(), dtype=float32)\n",
      " 6/29 [=====>........................] - ETA: 3:43tf.Tensor(0.0791475, shape=(), dtype=float32)\n",
      " 7/29 [======>.......................] - ETA: 3:33tf.Tensor(0.110744745, shape=(), dtype=float32)\n",
      " 8/29 [=======>......................] - ETA: 3:24tf.Tensor(0.23782407, shape=(), dtype=float32)\n",
      " 9/29 [========>.....................] - ETA: 3:14tf.Tensor(0.16029514, shape=(), dtype=float32)\n",
      "10/29 [=========>....................] - ETA: 3:04tf.Tensor(0.35417297, shape=(), dtype=float32)\n",
      "11/29 [==========>...................] - ETA: 2:54tf.Tensor(0.14493951, shape=(), dtype=float32)\n",
      "12/29 [===========>..................] - ETA: 2:44tf.Tensor(0.62503505, shape=(), dtype=float32)\n",
      "13/29 [============>.................] - ETA: 2:35tf.Tensor(0.24431896, shape=(), dtype=float32)\n",
      "14/29 [=============>................] - ETA: 2:25tf.Tensor(0.16466211, shape=(), dtype=float32)\n",
      "15/29 [==============>...............] - ETA: 2:15tf.Tensor(0.34824023, shape=(), dtype=float32)\n",
      "16/29 [===============>..............] - ETA: 2:06tf.Tensor(0.17844948, shape=(), dtype=float32)\n",
      "17/29 [================>.............] - ETA: 1:56tf.Tensor(0.124591134, shape=(), dtype=float32)\n",
      "18/29 [=================>............] - ETA: 1:46tf.Tensor(0.110129975, shape=(), dtype=float32)\n",
      "19/29 [==================>...........] - ETA: 1:36tf.Tensor(0.25433552, shape=(), dtype=float32)\n",
      "20/29 [===================>..........] - ETA: 1:27tf.Tensor(0.32923332, shape=(), dtype=float32)\n",
      "21/29 [====================>.........] - ETA: 1:17tf.Tensor(0.13362929, shape=(), dtype=float32)\n",
      "22/29 [=====================>........] - ETA: 1:07tf.Tensor(0.324407, shape=(), dtype=float32)\n",
      "23/29 [======================>.......] - ETA: 58s tf.Tensor(0.1385599, shape=(), dtype=float32)\n",
      "24/29 [=======================>......] - ETA: 48stf.Tensor(0.076057106, shape=(), dtype=float32)\n",
      "25/29 [========================>.....] - ETA: 38stf.Tensor(0.19834813, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/29 [=========================>....] - ETA: 29stf.Tensor(0.19216084, shape=(), dtype=float32)\n",
      "27/29 [==========================>...] - ETA: 19stf.Tensor(0.27023983, shape=(), dtype=float32)\n",
      "28/29 [===========================>..] - ETA: 9s tf.Tensor(0.071048774, shape=(), dtype=float32)\n",
      "29/29 [==============================] - 281s 10s/step\n",
      "0.071048774 0.9529914 0.9612069\n"
     ]
    }
   ],
   "source": [
    "train(train_data, EPOCHS = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880952 0.90217394\n"
     ]
    }
   ],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PresRecall(model, data, class_threshold=0.5):\n",
    "    r = Recall()\n",
    "    p = Precision()\n",
    "\n",
    "    for test_input, test_val, y_true in data.as_numpy_iterator():\n",
    "        yhat = model.predict([test_input, test_val])\n",
    "        yhat = (np.concatenate(yhat) > class_threshold).astype(np.float32)\n",
    "        \n",
    "        r.update_state(y_true, yhat)\n",
    "        p.update_state(y_true,yhat) \n",
    "\n",
    "    print(\"recall:\",r.result().numpy(), \"Precision\",p.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(model, data, class_threshold=0.5):\n",
    "    label = []\n",
    "    predic = []\n",
    "    for test_input, test_val, y_true in data.as_numpy_iterator():\n",
    "        predic.append(model.predict([test_input, test_val]))\n",
    "        label.append(y_true)\n",
    "\n",
    "    label = np.concatenate( label, axis=0).tolist()\n",
    "    prediction = np.concatenate( predic, axis=0).tolist()\n",
    "    prediction = (np.concatenate(prediction) > class_threshold).astype(np.float32)\n",
    "\n",
    "    print(accuracy_score(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.99038464 Precision 0.94495416\n"
     ]
    }
   ],
   "source": [
    "PresRecall(siamese_model, test_data, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9595959595959596\n"
     ]
    }
   ],
   "source": [
    "Accuracy(siamese_model, test_data, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "predic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "predic = []\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    predic.append(siamese_model.predict([test_input, test_val]))\n",
    "    label.append(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "\"\"\"\n",
    "Python compute equal error rate (eer)\n",
    "ONLY tested on binary classification\n",
    "\n",
    ":param label: ground-truth label, should be a 1-d list or np.array, each element represents the ground-truth label of one sample\n",
    ":param pred: model prediction, should be a 1-d list or np.array, each element represents the model prediction of one sample\n",
    ":param positive_label: the class that is viewed as positive class when computing EER\n",
    ":return: equal error rate (EER)\n",
    "\"\"\"\n",
    "def compute_eer(label, pred, positive_label=1):\n",
    "    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n",
    "    fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred, positive_label)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # the threshold of fnr == fpr\n",
    "    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n",
    "    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "\n",
    "    # return the mean of eer from fpr and from fnr\n",
    "    eer = (eer_1 + eer_2) / 2\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equal error rate is 0.375\n"
     ]
    }
   ],
   "source": [
    "#rom compute_eer import compute_eer\n",
    "label = np.concatenate( label, axis=0).tolist()\n",
    "prediction = np.concatenate( predic, axis=0).tolist()\n",
    "prediction = (np.concatenate(prediction) > 0.55).astype(np.float32)\n",
    "eer = compute_eer(label, prediction)\n",
    "print('The equal error rate is {:.3f}'.format(eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.045*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equal error rate is 0.045\n"
     ]
    }
   ],
   "source": [
    "label = np.concatenate( label, axis=0).tolist()\n",
    "prediction = np.concatenate( predic, axis=0).tolist()\n",
    "prediction = (np.concatenate(prediction) > 0.55).astype(np.float32)\n",
    "eer = compute_eer(label, prediction)\n",
    "print('The equal error rate is {:.3f}'.format(eer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
